{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Why information extraction from natural language?\n",
      "=================================================\n",
      "\n",
      "Natural language is unstructured and it is important to extract information from text.\n",
      "\n",
      "- example extracting phone numbers, adresses and email address from web pages.\n",
      "\n",
      "For us it is very lucrative as deal titles and descriptions contain valuable information like:\n",
      "\n",
      "* Deal (free shipping, get X% off)\n",
      "* Product\n",
      "* Start and End dates\n",
      "* Restrictions\n",
      "\n",
      "So let us learn some basics about extraction of information from free text. \n",
      "\n",
      "Following is a high level overview of what the workflow of information extraction will look like.\n",
      "\n",
      "![Information Extraction](http://nltk.org/images/ie-architecture.png)\n",
      "\n",
      "We will not touch relation extraction as it is advanced topic. \n",
      "\n",
      "Also I can show you some of the deal specific extractors we have put together but in the class I will focus on general examples as we are running on a tight schedule."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import re\n",
      "import pprint\n",
      "document = 'Save 20% off on regular, sale and clearance prices, including select fine & fashion jewelry + 15% on home, select watches, shoes, coats, suits, dresses, lingerie, men?s suit separates & sport coats. Plus free shipping on orders over $99. Exclusions apply. Expires on 12/19/2013.'\n",
      "sentences = nltk.sent_tokenize(document)\n",
      "# we are performing sentence segmentation here\n",
      "pprint.pprint(sentences)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Save 20% off on regular, sale and clearance prices, including select fine & fashion jewelry + 15% on home, select watches, shoes, coats, suits, dresses, lingerie, men?s suit separates & sport coats.',\n",
        " 'Plus free shipping on orders over $99.',\n",
        " 'Exclusions apply.',\n",
        " 'Expires on 12/19/2013.']\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# next is tokenization\n",
      "sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
      "pprint.pprint(sentences)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['Save',\n",
        "  '20',\n",
        "  '%',\n",
        "  'off',\n",
        "  'on',\n",
        "  'regular',\n",
        "  ',',\n",
        "  'sale',\n",
        "  'and',\n",
        "  'clearance',\n",
        "  'prices',\n",
        "  ',',\n",
        "  'including',\n",
        "  'select',\n",
        "  'fine',\n",
        "  '&',\n",
        "  'fashion',\n",
        "  'jewelry',\n",
        "  '+',\n",
        "  '15',\n",
        "  '%',\n",
        "  'on',\n",
        "  'home',\n",
        "  ',',\n",
        "  'select',\n",
        "  'watches',\n",
        "  ',',\n",
        "  'shoes',\n",
        "  ',',\n",
        "  'coats',\n",
        "  ',',\n",
        "  'suits',\n",
        "  ',',\n",
        "  'dresses',\n",
        "  ',',\n",
        "  'lingerie',\n",
        "  ',',\n",
        "  'men',\n",
        "  '?',\n",
        "  's',\n",
        "  'suit',\n",
        "  'separates',\n",
        "  '&',\n",
        "  'sport',\n",
        "  'coats',\n",
        "  '.'],\n",
        " ['Plus', 'free', 'shipping', 'on', 'orders', 'over', '$', '99', '.'],\n",
        " ['Exclusions', 'apply', '.'],\n",
        " ['Expires', 'on', '12/19/2013', '.']]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# next perform part of speech tagging\n",
      "sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
      "pprint.pprint(sentences)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[('Save', 'NNP'),\n",
        "  ('20', 'CD'),\n",
        "  ('%', 'NN'),\n",
        "  ('off', 'IN'),\n",
        "  ('on', 'IN'),\n",
        "  ('regular', 'JJ'),\n",
        "  (',', ','),\n",
        "  ('sale', 'NN'),\n",
        "  ('and', 'CC'),\n",
        "  ('clearance', 'NN'),\n",
        "  ('prices', 'NNS'),\n",
        "  (',', ','),\n",
        "  ('including', 'VBG'),\n",
        "  ('select', 'NN'),\n",
        "  ('fine', 'NN'),\n",
        "  ('&', 'CC'),\n",
        "  ('fashion', 'NN'),\n",
        "  ('jewelry', 'NN'),\n",
        "  ('+', ':'),\n",
        "  ('15', 'CD'),\n",
        "  ('%', 'NN'),\n",
        "  ('on', 'IN'),\n",
        "  ('home', 'NN'),\n",
        "  (',', ','),\n",
        "  ('select', 'NN'),\n",
        "  ('watches', 'NNS'),\n",
        "  (',', ','),\n",
        "  ('shoes', 'VBZ'),\n",
        "  (',', ','),\n",
        "  ('coats', 'NNS'),\n",
        "  (',', ','),\n",
        "  ('suits', 'NNS'),\n",
        "  (',', ','),\n",
        "  ('dresses', 'NNS'),\n",
        "  (',', ','),\n",
        "  ('lingerie', 'VBP'),\n",
        "  (',', ','),\n",
        "  ('men', 'NNS'),\n",
        "  ('?', '.'),\n",
        "  ('s', 'NNS'),\n",
        "  ('suit', 'NN'),\n",
        "  ('separates', 'NNS'),\n",
        "  ('&', 'CC'),\n",
        "  ('sport', 'NN'),\n",
        "  ('coats', 'NNS'),\n",
        "  ('.', '.')],\n",
        " [('Plus', 'NNP'),\n",
        "  ('free', 'JJ'),\n",
        "  ('shipping', 'NN'),\n",
        "  ('on', 'IN'),\n",
        "  ('orders', 'NNS'),\n",
        "  ('over', 'IN'),\n",
        "  ('$', '$'),\n",
        "  ('99', 'CD'),\n",
        "  ('.', '.')],\n",
        " [('Exclusions', 'NNS'), ('apply', 'RB'), ('.', '.')],\n",
        " [('Expires', 'NNS'), ('on', 'IN'), ('12/19/2013', 'CD'), ('.', '.')]]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hang on\n",
      "=======\n",
      "\n",
      "What did we do here? \n",
      "\n",
      "We performed something known as Part-of-Speech or POS tagging on words here. \n",
      "\n",
      "What is part of speech tagging? \n",
      "\n",
      "The process of classifying words into their parts of speech and labeling them accordingly is known as *part-of-speech tagging*, POS-tagging, or simply tagging. Parts of speech are also known as word classes or lexical categories. The collection of tags used for a particular task is known as a tagset. \n",
      "\n",
      "This is very important in understanding words that make up sentences and training models for information extraction and classification. \n",
      "\n",
      "![POS Tags](http://3.bp.blogspot.com/-IEOkrijtOZY/UbCcnoX7b_I/AAAAAAAAAEU/lVRN_6jHJA0/s1600/tagset.png)\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most basic form of information extraction is called *NP-Chunking*. It is a form of *chunking* one of very popular information extraction algorithms."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"), (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"),  (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
      "pprint.pprint(sentence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('the', 'DT'),\n",
        " ('little', 'JJ'),\n",
        " ('yellow', 'JJ'),\n",
        " ('dog', 'NN'),\n",
        " ('barked', 'VBD'),\n",
        " ('at', 'IN'),\n",
        " ('the', 'DT'),\n",
        " ('cat', 'NN')]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* In order to create an NP-chunker, we will first define a chunk grammar, consisting of rules that indicate how sentences should be chunked. In this case, we will define a simple grammar with a single regular-expression rule. \n",
      "* This rule says that an NP chunk should be formed whenever the chunker finds an optional determiner (DT) followed by any number of adjectives (JJ) and then a noun (NN). \n",
      "* Using this grammar, we create a chunk parser, and test it on our example sentence. \n",
      "* The result is a tree, which we can either print, or display graphically."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this is our grammar\n",
      "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
      "cp = nltk.RegexpParser(grammar)\n",
      "result = cp.parse(sentence)\n",
      "pprint.pprint(result)\n",
      "#result.draw()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tree('S', [Tree('NP', [('the', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN')]), ('barked', 'VBD'), ('at', 'IN'), Tree('NP', [('the', 'DT'), ('cat', 'NN')])])\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![tag_drawn](http://nltk.org/book/tree_images/ch07-tree-1.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chunk Representation\n",
      "====================\n",
      "\n",
      "There two ways to represent chunks:\n",
      "\n",
      "* Used as Trees #as example above \n",
      "* Tag format:\n",
      "   - most widespread file representation uses IOB tags. In this scheme, each token is tagged with one of three special chunk tags, I (inside), O (outside), or B (begin). \n",
      "   - A token is tagged as B if it marks the beginning of a chunk. \n",
      "   - Subsequent tokens within the chunk are tagged I. \n",
      "   - All other tokens are tagged O. \n",
      "   - The B and I tags are suffixed with the chunk type, e.g. B-NP, I-NP. Of course, it is not necessary to specify a chunk type for tokens that appear outside a chunk, so these are just labeled O. \n",
      "\n",
      "![IOB format](http://nltk.org/images/chunk-tagrep.png)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}